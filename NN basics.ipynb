{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66da5e6-e7ee-43cf-9e75-755a9495bb31",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron and Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3deb5f-608c-42b8-b087-ed82505e38a8",
   "metadata": {},
   "source": [
    "## 1 Forward Propagation 前向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb38f61-dd04-406e-8148-5404ef365029",
   "metadata": {},
   "source": [
    "Simple steps to make a prediction:\n",
    "1. Intialize the weights and baises (randomly assign numbers)\n",
    "2. Compute weighted sum at each node\n",
    "3. Compute node activation\n",
    "4. Use Forward Propagation to propagate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d250b2d-d365-415d-a83e-5f3a9c4cada6",
   "metadata": {},
   "source": [
    "<img src=\"http://cocl.us/neural_network_example\" alt=\"Neural Network Example\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a315ccb7-744a-4905-9938-a9f9697d042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\rui-s\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "\n",
    "# %pip install --user numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72689ba-cf0a-4213-a97a-1fb91b9bbee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2934b53-97a9-40b3-acaa-0f4938d7e902",
   "metadata": {},
   "source": [
    "### 1.1 给Weights和Biases随机取值：</br>\n",
    "np.random.uniform(low, high, size)从均匀分布的区域[low, high)中随机取样\n",
    "\n",
    "1. low：采样区域的下界，float类型或者int类型或者数组类型或者迭代类型，默认值为0 \n",
    "2. high：采样区域的上界，float类型或者int类型或者数组类型或者迭代类型，默认值为1 \n",
    "3. size：输出样本的数目(int类型或者tuple类型或者迭代类型) \n",
    "4. 返回对象：ndarray类型，形状和size中的数值一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a715fa9d-b99a-4502-a6bf-f43eb623c2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [0.37 0.61 0.95 0.83 0.85 0.75]\n",
      "Biases:  [0.41 0.45 0.56]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the weights and biases by randomly generating numbers \n",
    "# Here: sample from an Uniformly distributed space in [0, 1)\n",
    "\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2) # initialize the weights\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2) # initialize the biases\n",
    "\n",
    "print(\"Weights: \", weights)\n",
    "print(\"Biases: \", biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5bb86",
   "metadata": {},
   "source": [
    "## 1.2 用上面的权重和偏差计算预测值\n",
    "Compute the output for a given input, $x_1$ and $x_2$. </br>\n",
    "Given: $x_1 = 0.5$ , $x_2 = 0.85$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4c46ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5 and x2 is 0.85\n",
      "The weighted sum of the inputs at the first node in the hidden layer is 1.1135\n",
      "The weighted sum of the inputs at the second node in the hidden layer is 1.6305\n"
     ]
    }
   ],
   "source": [
    "x_1 = 0.5 # input 1\n",
    "x_2 = 0.85 # input 2\n",
    "print('x1 is {} and x2 is {}'.format(x_1, x_2))\n",
    "\n",
    "# Compute the weighted sum of inputs for the nodes of the hidden layer\n",
    "\n",
    "z_11 = x_1 * weights[0] + x_2 * weights[1] + biases[0]\n",
    "print('The weighted sum of the inputs at the first node in the hidden layer is {}'.format(z_11))\n",
    "\n",
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + biases[1]\n",
    "print('The weighted sum of the inputs at the second node in the hidden layer is {}'.format(np.around(z_12, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0f882",
   "metadata": {},
   "source": [
    "Assuming a sigmoid activation function, compute the activated values for the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e3a94bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.7528\n",
      "The activation of the second node in the hidden layer is 0.8362\n"
     ]
    }
   ],
   "source": [
    "a_11 = 1.0 / (1.0 + np.exp(-z_11))\n",
    "print('The activation of the first node in the hidden layer is {}'.format(np.around(a_11, decimals=4)))\n",
    "\n",
    "a_12 = 1.0 / (1.0 + np.exp(-z_12))\n",
    "print('The activation of the second node in the hidden layer is {}'.format(np.around(a_12, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd6afa",
   "metadata": {},
   "source": [
    "Compute the output of the network as the activation of the node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6da67e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the node in the output layer is 1.827\n",
      "The output of the network for x1 = 0.5 and x2 = 0.85 is 0.8614\n"
     ]
    }
   ],
   "source": [
    "z_2 = a_11 * weights[4] + a_12 * weights[5] + biases[2]\n",
    "print('The weighted sum of the inputs at the node in the output layer is {}'.format(np.around(z_2, decimals=4)))\n",
    "\n",
    "a_2 = 1.0 / (1.0 + np.exp(-z_2))\n",
    "print('The output of the network for x1 = 0.5 and x2 = 0.85 is {}'.format(np.around(a_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185a5ed",
   "metadata": {},
   "source": [
    "## 1.3 Generalize the network-initialization process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652aeeba",
   "metadata": {},
   "source": [
    "Obviously, neural networks for real problems are composed of many hidden layers and many more nodes in each layer. So, we can't continue making predictions using this very inefficient approach of computing the weighted sum at each node and the activation of each node manually.\n",
    "</br>\n",
    "We can code an automatic way of making predictions.</br>\n",
    "\n",
    "A general network would take $n$ inputs, would have many hidden layers, each hidden layer having $m$ nodes, and would have an output layer. \n",
    "\n",
    "Although the network is showing one hidden layer, but we will code the network to have many hidden layers. Similarly, although the network shows an output layer with one node, we will code the network to have more than one node in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9cf70",
   "metadata": {},
   "source": [
    "<img src=\"http://cocl.us/general_neural_network\" alt=\"Neural Network General\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c4d3b",
   "metadata": {},
   "source": [
    "### 1.3.1 Build the network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfe91d",
   "metadata": {},
   "source": [
    "Formally defining the structure of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faacd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structure of the network\n",
    "\n",
    "n = 2                    # number of inputs\n",
    "num_hidden_layers = 2    # number of hidden layers\n",
    "m = [2, 2]               # number of nodes in each hidden layer\n",
    "num_nodes_output = 1     # number of nodes in the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4ef6e",
   "metadata": {},
   "source": [
    "#### - 1 Initialize the weights and biases 初始化权值和偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f83fb",
   "metadata": {},
   "source": [
    "Initialize the weights and biases in the network to random numbers.\n",
    "\n",
    "The logic is:\n",
    "1. To calculate the weights and biases, we need to know how many numbers to generate - which depends on the number of nodes on each layer\n",
    "2. Fully connected layers: Weights are needed for each node in one layer corresponding with each node in the previous layer\n",
    "    1. We can traverse each layer, from 1st hidden layer -> the output layer\n",
    "    2. Num of weights: num of nodes of previous layer (from input -> the last hidden layer)\n",
    "    3. Num of biases: numb of nodes of current layer (from 1st hidden layer -> output layer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c3a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.29, 0.1 ]), 'biases': array([0.82])}, 'node_2': {'weights': array([0.94, 0.04]), 'biases': array([0.89])}}, 'layer_2': {'node_1': {'weights': array([0.61, 0.51]), 'biases': array([0.04])}, 'node_2': {'weights': array([0.35, 0.58]), 'biases': array([0.07])}}, 'output': {'node_1': {'weights': array([0.67, 0.93]), 'biases': array([0.11])}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "num_nodes_previous = n      # number of nodes in the previous layer, initialized by input nodes\n",
    "\n",
    "network = {}                # initialize network in an empty dictionary\n",
    "\n",
    "# Loop through each layer and randomly initialize the weights and biases associated with each node\n",
    "# Adding 1 to the number of hidden layers in order to include the output layer\n",
    "\n",
    "for layer in range(num_hidden_layers + 1):\n",
    "    \n",
    "    # determine name of the layer & num_nodes in this layer\n",
    "    if layer == num_hidden_layers:\n",
    "        # it's the last layer we iterate - output layer\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(layer + 1)  # naming\n",
    "        num_nodes = m[layer]\n",
    "        \n",
    "    # initialize weights and biases associated with each node in the current layer\n",
    "    network[layer_name] = {}        # store all weights and biases for this layer\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node + 1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals = 2),\n",
    "            'biases': np.around(np.random.uniform(size=1), decimals = 2)\n",
    "        }\n",
    "    \n",
    "    # Update layer nodes to the next one\n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c36408",
   "metadata": {},
   "source": [
    "Initialization for network weights and biases is done.\n",
    "\n",
    "Put the initialization process into a function: `initialize_network()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff737a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    \n",
    "    num_nodes_previous = num_inputs   # number of nodes in the previous layer, initialized by input nodes\n",
    "    network = {}                      # initialize network in an empty dictionary\n",
    "\n",
    "    # Loop through each layer and randomly initialize the weights and biases associated with each node\n",
    "\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        # determine name of the layer & num_nodes in this layer\n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output'    # the last layer is output layer\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1)  \n",
    "            num_nodes = num_nodes_hidden[layer]\n",
    "            \n",
    "        # initialize weights and biases associated with each node in the current layer\n",
    "        network[layer_name] = {}        # store all weights and biases for this layer\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node + 1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals = 2),\n",
    "                'biases': np.around(np.random.uniform(size=1), decimals = 2)\n",
    "            }\n",
    "        \n",
    "        # Update layer nodes to the next one\n",
    "        num_nodes_previous = num_nodes\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80cdfb2",
   "metadata": {},
   "source": [
    "Use the `initialize_network()` function to create a network that:\n",
    "\n",
    "1. takes 5 inputs\n",
    "2. has three hidden layers\n",
    "3. has 3 nodes in the first layer, 2 nodes in the second layer, and 3 nodes in the third layer\n",
    "4. has 1 node in the output layer\n",
    "\n",
    "Call the network **small_network**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20f6cd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.45, 0.51, 0.05, 0.51, 0.53]), 'biases': array([0.75])}, 'node_2': {'weights': array([0.38, 0.99, 0.88, 0.41, 0.33]), 'biases': array([0.3])}, 'node_3': {'weights': array([0.72, 0.74, 0.57, 0.65, 0.14]), 'biases': array([0.67])}}, 'layer_2': {'node_1': {'weights': array([0.61, 0.39, 0.12]), 'biases': array([0.45])}, 'node_2': {'weights': array([0.55, 0.18, 0.81]), 'biases': array([0.46])}}, 'layer_3': {'node_1': {'weights': array([0.56, 0.65]), 'biases': array([0.01])}, 'node_2': {'weights': array([0.37, 0.39]), 'biases': array([0.97])}, 'node_3': {'weights': array([0.72, 0.39]), 'biases': array([0.94])}}, 'output': {'node_1': {'weights': array([0.2 , 0.31, 0.68]), 'biases': array([0.77])}}}\n"
     ]
    }
   ],
   "source": [
    "# Excercise:\n",
    "\n",
    "small_network = initialize_network(5, 3, [3, 2, 3], 1)\n",
    "print(small_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686abd52",
   "metadata": {},
   "source": [
    "#### - 2 Compute Weighted Sum at Each Node 单个node上做加权求和\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0dfe2",
   "metadata": {},
   "source": [
    "Weighted sum at each node: Dot product of the inputs and weights, plus the bias.\n",
    "\n",
    "$Z = W * X + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d5d9d",
   "metadata": {},
   "source": [
    "But start from simple ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc34e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computed_weighted_sum(inputs, weights, biases):\n",
    "    return np.sum(inputs * weights) + biases  # dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d490ba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n",
      "The weighted sum at the first node in the first hidden layer is 1.4835\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "\n",
    "np.random.seed(12)  # set seed\n",
    "\n",
    "# Generate random inputs\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)    \n",
    "print('The inputs to the network are {}'.format(inputs))\n",
    "\n",
    "# Compute the weighted sum at the first node in the first hidden layer\n",
    "# used the \"small_network\" defined above\n",
    "weights = small_network['layer_1']['node_1']['weights']\n",
    "biases = small_network['layer_1']['node_1']['biases']\n",
    "\n",
    "weighted_sum = computed_weighted_sum(inputs, weights, biases)\n",
    "print('The weighted sum at the first node in the first hidden layer is {}'.\n",
    "      format(np.around(weighted_sum[0], decimals=4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5710dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AI generated code:\n",
    "# def computed_weighted_sum(inputs, weights, biases):\n",
    "#     \"\"\"\n",
    "#     Compute the weighted sum of inputs for a given layer.\n",
    "    \n",
    "#     Parameters:\n",
    "#     inputs (list): List of inputs to the layer.\n",
    "#     weights (list): List of weights for each node in the layer.\n",
    "#     biases (list): List of biases for each node in the layer.\n",
    "    \n",
    "#     Returns:\n",
    "#     list: Weighted sum for each node in the layer.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Compute the weighted sum of inputs for each node\n",
    "#     z = np.around(np.dot(weights, inputs) + biases, decimals=4)\n",
    "    \n",
    "#     return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb0d45",
   "metadata": {},
   "source": [
    "#### - 3 Compute Node Activation 单个node上的激活值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ceeef1",
   "metadata": {},
   "source": [
    "Define the non-linear transformation of the input using Sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc7485b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / 1.0 + np.exp(-x)   # sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e86065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the first node in the first hidden layer is 1.2268\n"
     ]
    }
   ],
   "source": [
    "node_output = sigmoid(weighted_sum)  # apply sigmoid activation function\n",
    "\n",
    "# Or, in a complete way: node_output  = node_activation(compute_weighted_sum(inputs, node_weights, node_bias))\n",
    "\n",
    "print('The output of the first node in the first hidden layer is {}'.\n",
    "      format(np.around(node_output[0], decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc907cb",
   "metadata": {},
   "source": [
    "### 1.3.2 Forward Propagation in the generalized network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ebf17",
   "metadata": {},
   "source": [
    "Apply the *compute_weighted_sum* and *node_activation* functions to each node in the network and propagates the data all the way to the output layer and outputs a prediction for each node in the output layer.\n",
    "\n",
    "The way we are going to accomplish this is through the following procedure:\n",
    "\n",
    "1. Start with the input layer as the input to the first hidden layer.\n",
    "2. Compute the weighted sum at the nodes of the current layer.\n",
    "3. Compute the output of the nodes of the current layer.\n",
    "4. Set the output of the current layer to be the input to the next layer.\n",
    "5. Move to the next layer in the network.\n",
    "6. Repeat steps 2 - 5 until we compute the output of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1255d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(network, inputs):\n",
    "    \"\"\"\n",
    "    Perform forward propagation through the network.\n",
    "    \n",
    "    Parameters:\n",
    "    network (dict): The neural network structure with weights and biases.\n",
    "    inputs (list): The input data to the network.\n",
    "    \n",
    "    Returns:\n",
    "    (dict): The outputs of each layer in the network.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = list(inputs)   # the input layer is the input to the 1st hidden layer\n",
    "    \n",
    "    for layer_name, layer in network.items():\n",
    "        layer_outputs = []  # initialize layer outputs\n",
    "        \n",
    "        for node_name, node in layer.items():\n",
    "            # Compute the weighted sum\n",
    "            weighted_sum = computed_weighted_sum(inputs, node['weights'], node['biases'])\n",
    "            \n",
    "            # Apply activation function\n",
    "            output = sigmoid(weighted_sum)\n",
    "            \n",
    "            # Store the output of the node\n",
    "            layer_outputs.append(output[0])\n",
    "        \n",
    "        # Store the outputs of the current layer\n",
    "        outputs[layer_name] = np.around(layer_outputs, decimals=4)\n",
    "        \n",
    "        # Update inputs for the next layer\n",
    "        inputs = np.array(layer_outputs)\n",
    "    \n",
    "\n",
    "    \n",
    "    return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
